{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 4.95 s, total: 8.11 s\n",
      "Wall time: 2.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "#import tensorflow.keras.utils.to_categorical\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from emnist import extract_training_samples\n",
    "from emnist import extract_test_samples\n",
    "from tensorflow.keras import utils\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global para's\n",
    "\n",
    "img_width, img_height = 28, 28\n",
    "leaky_relu_alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_training_samples('balanced')\n",
    "X_test, y_test = extract_test_samples('balanced')\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "\n",
    "'''\n",
    "CNN's require a different formal of input data as compared to MLP;\n",
    "this function reshapes the image data accordingly.\n",
    "\n",
    "Reshapring for 3D cnn format since we are using black and white images, gotta made it 3dim.\n",
    "\n",
    "'''\n",
    "\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "X_trainCNN, y_trainCNN = extract_training_samples('balanced')\n",
    "X_testCNN, y_testCNN = extract_test_samples('balanced')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_trainCNN = X_trainCNN.reshape(X_trainCNN.shape[0], 1, img_width, img_height)\n",
    "    X_testCNN = X_testCNN.reshape(X_testCNN.shape[0], 1, img_width, img_height)\n",
    "    CNNinput_shape = (1, img_width, img_height)\n",
    "else:\n",
    "    X_trainCNN = X_trainCNN.reshape(X_trainCNN.shape[0], img_width, img_height, 1)\n",
    "    X_testCNN = X_testCNN.reshape(X_testCNN.shape[0], img_width, img_height, 1)\n",
    "    CNNinput_shape = (img_width, img_height, 1)\n",
    "    \n",
    "X_trainCNN = X_trainCNN / 255\n",
    "X_testCNN = X_testCNN / 255\n",
    "    \n",
    "y_trainCNN = utils.to_categorical(y_trainCNN)\n",
    "y_testCNN = utils.to_categorical(y_testCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Image rotation of 40 degree's (minics difference angles of writing)\n",
    "Shear, Vertical, Horizontal shifts by 0.08 (minic displacements and cursive fonts)\n",
    "Zoom's in by 0.08 (minics alphabets size difference)\n",
    "\n",
    "'''\n",
    "\n",
    "img_gen = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False,  \n",
    "    featurewise_std_normalization=False,  \n",
    "    samplewise_std_normalization=False,  \n",
    "    zca_whitening=False,  \n",
    "    rotation_range=34,\n",
    "    #shear_range = 30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    #zoom_range = [-0.5,0.5],\n",
    "    horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_model():\n",
    "\n",
    "    '''\n",
    "    {784 - [32C3-32C3-32C5S2] - [64C3-64C3-64C5S2] - 128 - 47}\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = 3, kernel_initializer='he_uniform',input_shape = CNNinput_shape))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = 3, kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size = 3, kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size = 3, kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "    model.add(BatchNormalization())\n",
    "        \n",
    "    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 4, kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=leaky_relu_alpha))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "               \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Aug train only\n",
    "\n",
    "CNNHistory = CNN_model.fit(img_gen.flow(X_trainCNN,y_trainCNN), validation_data=(X_testCNN, y_testCNN), batch_size=100,epochs=75, verbose=2)\n",
    "CNN_scores = CNN_model.evaluate(X_testCNN, y_testCNN, verbose=2)\n",
    "\n",
    "print(\"Baseline Error: %.2f%%\" % (100-CNN_scores[1]*100))\n",
    "print(f'Test loss for base CNN: {CNN_scores[0]} / Test accuracy: {CNN_scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CNNHistory.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(CNNHistory.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('CNN model / validation accuracies')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(CNNHistory.history['loss'], label='Training loss')\n",
    "plt.plot(CNNHistory.history['val_loss'], label='Validation loss')\n",
    "plt.title('CNN model / validation loss values')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
